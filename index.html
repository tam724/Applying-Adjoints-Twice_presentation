<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Appying Adjoints Twice</title>

		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300..700&display=swap" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&family=Quicksand:wght@300..700&display=swap" rel="stylesheet">
		
		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/serif.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<!-- Title frame -->
				<section class="center">
					<h3 style="margin-bottom: 100px;">
						Applying Adjoints Twice: An Efficient Gradient Implementation for Models with Linear Structure with Applications in Reconstruction for EPMA
					</h3>
					<div height="50px"></div>
					<p><strong>Tamme Claus</strong></p>
					<p>ACoM, Applied and Computational Mathematics, RWTH Aachen University</p>
					<p>2024</p>
				</section>
				
				<!-- Motivation -->
				<section style="text-align: left;">
					<h3>
						Motivation - from Linear Algebra
					</h3>
					Consider Matrix Multiplication ($N >> I, J$):
					<div class="r-stack">
						<span class="fragment fade-out" data-fragment-index="1">\[
							\underbrace{\begin{pmatrix}
							&   &   \\
							& \Sigma^{(ij)} &   \\
							&   &   \end{pmatrix}^{\color{white}{T}}}_{I \times J} = 
							\color{white}{\Bigg(}
							\underbrace{\begin{pmatrix}
							— & h^{(1)} & — \\
							— & h^{(i)} & — \\
							— & h^{(I)} & — \\
							\end{pmatrix}}_{I \times N} 
							\cdot{}
							\color{white}{\Bigg(}
							\underbrace{\boldsymbol{A}^{\color{white}{*}}}_{N \times N}
							\color{white}{\Bigg)
							}
							\cdot{}
							\underbrace{
							\begin{pmatrix}
								| & | & | \\
								g^{(1)} &  g^{(j)} & g^{(J)} \\
								| & | & | \\
							\end{pmatrix}}_{N \times J}
							\color{white}{\Bigg)}
						\]</span>
						<span class="fragment fade-in-then-out" data-fragment-index="1">\[
							\underbrace{\begin{pmatrix}
							&   &   \\
							& \Sigma^{(ij)} &   \\
							&   &   \end{pmatrix}^{\color{white}{T}}}_{I \times J} = 
							\color{blue}{\Bigg(}
							\underbrace{\begin{pmatrix}
							— & h^{(1)} & — \\
							— & h^{(i)} & — \\
							— & h^{(I)} & — \\
							\end{pmatrix}}_{I \times N} 
							\cdot{}
							\color{white}{\Bigg(}
							\underbrace{\boldsymbol{A}^{\color{white}{*}}}_{N \times N}
							\color{blue}{\Bigg)
							}
							\cdot{}
							\underbrace{
							\begin{pmatrix}
								| & | & | \\
								g^{(1)} &  g^{(j)} & g^{(J)} \\
								| & | & | \\
							\end{pmatrix}}_{N \times J}
							\color{white}{\Bigg)}
						\]</span>
						<span class="fragment fade-in-then-out" data-fragment-index="2">\[
							\underbrace{\begin{pmatrix}
							&   &   \\
							& \Sigma^{(ij)} &   \\
							&   &   \end{pmatrix}^{\color{white}{T}}}_{I \times J} = 
							\color{white}{\Bigg(}
							\underbrace{\begin{pmatrix}
							— & h^{(1)} & — \\
							— & h^{(i)} & — \\
							— & h^{(I)} & — \\
							\end{pmatrix}}_{I \times N} 
							\cdot{}
							\color{red}{\Bigg(}
							\underbrace{\boldsymbol{A}^{\color{white}{*}}}_{N \times N}
							\color{white}{\Bigg)
							}
							\cdot{}
							\underbrace{
							\begin{pmatrix}
								| & | & | \\
								g^{(1)} &  g^{(j)} & g^{(J)} \\
								| & | & | \\
							\end{pmatrix}}_{N \times J}
							\color{red}{\Bigg)}
						\]</span>
						<span class="fragment fade-in" data-fragment-index="3">\[
							\underbrace{\begin{pmatrix}
							&   &   \\
							& \Sigma^{(ij)} &   \\
							&   &   \end{pmatrix}^{\color{white}{T}}}_{I \times J} = 
							\color{blue}{\Bigg(}
							\underbrace{\begin{pmatrix}
							— & h^{(1)} & — \\
							— & h^{(i)} & — \\
							— & h^{(I)} & — \\
							\end{pmatrix}}_{I \times N} 
							\cdot{}
							\color{red}{\Bigg(}
							\underbrace{\boldsymbol{A}^{\color{white}{*}}}_{N \times N}
							\color{blue}{\Bigg)
							}
							\cdot{}
							\underbrace{
							\begin{pmatrix}
								| & | & | \\
								g^{(1)} &  g^{(j)} & g^{(J)} \\
								| & | & | \\
							\end{pmatrix}}_{N \times J}
							\color{red}{\Bigg)}
						\]</span>
						<!-- <span style="background-color:#fff;" class="fragment fade-in" data-fragment-index="6">\[
							\underbrace{\begin{pmatrix}
							&   &   \\
							& \Sigma^{(ij)} &   \\
							&   &   \end{pmatrix}^{\color{black}{T}}}_{J \times I} = 
							\color{white}{\Bigg(}
							\underbrace{\begin{pmatrix}
							— & g^{(1)} & — \\
							— & g^{(j)} & — \\
							— & g^{(J)} & — \\
							\end{pmatrix}}_{J \times N}
							\cdot{}
							\color{white}{\Bigg(}
							\underbrace{\boldsymbol{A}^*}_{N \times N}
							\color{white}{\Bigg)}
							\cdot{}
							\underbrace{
							\begin{pmatrix}
								| & | & | \\
								h^{(1)} &  h^{(i)} & h^{(I)} \\
								| & | & | \\
							\end{pmatrix}}_{N \times I}
							\color{white}{\Bigg)}
						\]</span> -->
					</div>
					<p>where to bracket?</p>
					<p style="text-align: center" class="fragment fade-in" data-fragment-index="4">
						different computational costs: $\color{red}{J\times N^2 + IJ\times N} \text{ or } \color{blue}{I\times N^2 + IJ\times N}$
					</p>
						<span class="fragment fade-in" data-fragment-index="5">
							<ul>
								<li>
									what happens if $\boldsymbol A$ is more general, e.g. "solution of a linear system / (linear, linearized) weak form" instead of "matrix multiplication"?
									\[
										\boldsymbol A g^{(i)} = \{u \in V \, | \, a(u, v) = \langle g^{(i)}, v \rangle \quad \forall v \in V\}
									\]
								</li>
								<li>
									what happens if $\boldsymbol A$ is a derivative (structure: chain rule, product rule, ...)?
									\[
										\boldsymbol A g^{(j)} = \frac{\partial f(h(w))}{\partial v}\frac{\partial h(w)}{\partial w}g^{(i)}
									\]
								</li>
							</ul>
						</span>
						<span class="fragment fade-in" data-fragment-index="6">
							In general (reduced cost, if $J < I$):
							\[
								\underbrace{\Sigma^T}_{J\times I} = \underbrace{G^T}_{J \times \infty} \cdot{}  \underbrace{A^*}_{\infty \times \infty} \cdot{} \underbrace{H^T}_{\infty \times I}
							\]
							where $\boldsymbol A ^* $is the <em>adjoint </em> operator.
						</span>
				</section>

				<!-- Material Reconstruction in EPMA-->
				<section style="text-align: left;">
					<h3>Material Reconstruction in Electron Probe Microanalysis (EPMA)</h3>
					<div style="display:flex;">
						<div class="r-stack" style="flex:1">
							<div class="fragment fade-out" data-fragment-index="1">
								<img src="figures/01_material.jpg" alt="Material">
							</div>
							<div class="fragment fade-in-then-out" data-fragment-index="1">
								<video data-autoplay>
									<source src="figures/02_forward.webm" type="video/webm">
								</video>
							</div>
							<div class="fragment fade-in-then-out" data-fragment-index="2">
								<video data-autoplay>
									<source src="figures/03_ionization.webm" type="video/webm">
								</video>
							</div>
							<div class="fragment fade-in-then-out" data-fragment-index="3">
								<img src="figures/04_interaction_volume.jpg" alt="Interaction Volume">
							</div>
							<div class="fragment fade-in-then-out" data-fragment-index="4">
								<video data-autoplay>
									<source src="figures/05_linescan.webm" type="video/webm">
								</video>
							</div>
							<div class="fragment fade-in-then-out" data-fragment-index="5">
								<video data-autoplay>
									<source src="figures/06_linescan.webm" type="video/webm">
								</video>
							</div>
							<div class="fragment fade-in-then-out" data-fragment-index="6">
								<video data-autoplay>
									<source src="figures/07_linescan.webm" type="video/webm">
								</video>
							</div>
						</div>
						<div style="flex:1">
							<ul>
								<li>Example: Consider a two-phase material with <span style="color: orange">Material A</span> and <span style="color: green;">Material B</span></li>
								<li>Shoot the sample with <span style="color:blue">electrons</span></li>
								<li><span style="color:blue">Electron</span> propagation is affected by scattering. (animated: different energies)</li>
								<li>Ionization and successive emission of characteristic x-rays (wavelength differs between <span style="color:orange">A-photons</span> and <span style="color:green">B-photons</span>)</li>
								<li>Detector measures the total wavelength-dispersive photon intensity (of <span style="color:orange">A-</span> and <span style="color:green">B-</span>photons)</li>
								<li>Spatial information gained via different beam positions (linescan),</li>
								<li>... with different beam angles</li>
								<li>... and different beam energies</li>
							</ul>
						</div>

					</div>
				</section>

				<!-- Gradients in Inverse Problems-->
				<section style="text-align: left;">
					<h3>Gradients in Inverse Problems</h3>
				</section>

				<!-- Riesz Representation Theorem/Def Adjoint -->
				<section style="text-align: left;">
					<h3>Riesz Representation Theorem/Definition of the Adjoint</h3>

					<h4>Riesz Representation Theorem</h4>
					<p>
						Let $(H, \langle \cdot{}, \cdot{} \rangle_H)$ be a (real) Hilbert space with inner product $\langle \cdot{}, \cdot{} \rangle_H$. For every continuous linear functional $f_\varphi \in H^*$ (the dual of $H$), there exists a unique vector $\varphi \in H$, called the <em>Riesz Representation</em> of $f_\varphi$, such that
						\[
							f_\varphi(x) = \langle \varphi, x \rangle_H \quad \forall x \in H
						\]
					</p>

					<h4>Definition: Adjoint Operator</h4>
					Let $(G, \langle \cdot{}, \cdot{} \rangle_G)$ be another (real) Hilbert space, $A:G\to H$ a continuous linear operator between $G$ and $H$ and $f_h \in  H^*$ a continuous linear functional.
					\[
						f_h(A(g)) = \langle h, A(g) \rangle_H \quad \forall g \in G
					\]
					$f_h(A(g))$ is also a continuous linear functional $f_\lambda(g)$ on $G$ with a representation $\lambda \in G$
					\[
						f_h(A(g)) = f_\lambda(g) = \langle \lambda, g \rangle_G := \langle A^*(h), g \rangle_G
					\]
				</section>

				<section style="text-align: left;">
					<h3>An adjoint method</h3>
					<p>
						Definition of the <em>adjoint</em> ($H, G$ Hilbert, $A: G \to H$ continuous, linear)
						\[
							\langle h, A(g) \rangle_H := \langle A^*(h), g \rangle_G \quad \forall h \in H \, \forall g \in G
						\]
					</p>
					<ul>
						<li>given multiple inputs $g^{(1)}, ... g^{(J)} \in G$, $h^{(1)}, ... h^{(I)} \in H$
						</li>
						<li> we want to compute
						</li>
					</ul>
					\[
					\Sigma^{(ij)} = \langle h^{(i)}, A(g^{(j)}) \rangle = \langle A^*(h^{(i)}), g^{(j)} \rangle 
					\]
					<h4>Pseudocode</h4>
					<div style="display:flex;">
						<div style="flex: 1;">
							<pre><code data-trim data-noescape>
								for j in range(1, J)
									v[j] = A(g[j])
									for i in range(1, I)
										Σ[i, j] = h[i] * v[j]
							</code></pre>
							\[\text{cost: } J\mathcal{C}(\texttt{A}) + IJ\mathcal{C}(\texttt{*})\]
						</div>
						<div style="flex: 1;">
							<pre><code data-trim data-noescape>
								for i in range(1, I)
									λ[j] = A*(h[i])
									for j in range(1, J)
										Σ[i, j] = g[j] * λ[j]
							</code></pre>
							\[\text{cost: } I\mathcal{C}(\texttt{A}) + IJ\mathcal{C}(\texttt{*})\]
						</div>
					</div>
				</section>

				<section style="text-align: left;">
					<section>
						<h3>Problem with linear structure</h3>
						<ul>
							<li>$m = \gamma_p$ with $\gamma_{(\cdot{})}: \mathbb{R}^{N} \to M$: parametrization</li>
							<li>$u^{(i)} \in V$ a state where $a_m(u^{(i)}, v) = b_m^{(i)}(v) \quad \forall v \in V$ with $b^{(i)}_m$ an excitation $\forall i\in [1, I]$</li>
							<li>$\Sigma^{(i, j)} = c^{(j)}_m(u^{(i)})$ a measurement with $c_m^{(j)}: V \to \mathbb{R}$ an extraction $\forall i=[1, I], j=[1, J]$</li>
							<li>$C = g_{\Sigma}$ with $g_{(\cdot{})}: \mathbb{R}^{I\times J} \to \mathbb{R}$ the objective</li>
							<li>we are interested in $\nabla_p C$</li>
						</ul>
						<h4>Naive Implementation (Sensitivity Equations)</h4>
						<ul>
							<li>$\dot{m}^{(n)} = \dot{\gamma}_p(e_n)$ $\forall n \in [1, N]$</li>
							<li>$\dot{u}^{(i, n)} \in V$ where $a_m(\dot{u}^{(i, n)}, v) + \dot{a}_m(u^{(i)}, v, \dot{m}^{(n)})=\dot{b}^{(i)}_m(v, \dot{m}^{(n)})$ $\forall i \in [1, I], \forall n \in [1, N]$</li>
							<li>$\dot{\Sigma}^{(i, j, n)} = c_m^{(j)}(\dot{u}^{(i, n)}) + \dot{c}_m^{(j)}(u^{(i)}, \dot{m}^{(n)})$</li>
							<li>$\dot{C}^{(n)} = \dot{g}_{\Sigma}(\dot{\Sigma}^{(:, :, n)})$</li>
							<li>$(\nabla_{p} C)_n = \dot{C}^{(n)}$</li>
						</ul>
						<h4>First Adjoint</h4>
						<ul>
							<li>$a_m(u, \lambda^{(j)}) = c_m^{(j)}(u) \quad \forall u \in U$, $\forall j \in [1, J]$</li>
							<li>$\Sigma^{(i, j)} = b_m^{(i)}(\lambda^{(j)})$</li>
							<li>$a_m(\bar{u}^{(j)}, v) = \sum_{i=1}^{I}\bar{\Sigma}$</li>
						</ul>
					</section>
					<section>
						<h3>Full System</h3> 
					</section>
				</section>

				<section style="text-align: left;">
					<h3>Notation</h3>
					<ul>
						<li>linear operator $f(x)$</li>
						<li>non-linear operator $f_x$</li>
						<li>tangent operator $\dot{f}_x(\dot{x}) = \frac{\partial f_x}{\partial x} \dot{x}$ (for linear $\dot{f}(\dot{x}) = f(\dot{x})$)</li>
						<li>adjoint operator $\bar{f}_x(\bar{y})$ defined by $\langle \bar{f}_x(\bar{y}), \dot{x} \rangle = \langle \bar{y}, \dot{f}_x{(\dot{x})} \rangle \quad \forall \bar{y}, \dot{x}$</li>
					</ul>
				</section>
				<section style="text-align: left;">
					<h3>(Simplified) abstract system</h3>
					We consider the following system ($m = \gamma_p$)
					<div style="display:flex;">
						<div style="flex: 1;">
							\begin{align*}
								a_m(u^{(i)}, v) + b^{(i)}(v) &= 0 \quad \forall v \in V \\
								\Sigma^{(i)} &= c(u^{(i)}) \\
								C &= g_{\boldsymbol \Sigma} \\
								\nabla_p C &= \text{TODO!}
							\end{align*}
						</div>
						<div style="flex: 1;">
							\begin{align*}
								\boldsymbol{\Sigma} &= (\Sigma^{(1)}, ..., \Sigma^{(I)})^T\\
								\boldsymbol{b}(v) &= (b^{(1)}(v), ... b^{(I)}(v))^T
							\end{align*}
						</div>
					</div>
					<div>
						<ul style="width: 100%">
							<li class="fragment fade-in" data-fragment-index="1">introduce a $\lambda \in V$ (fixed but yet unspecified "Lagrange-multiplier") 
								<div class="r-stack">
									<div class="fragment fade-in-then-out" data-fragment-index="1">
										\[
											\Sigma^{(i)} = c(u^{(i)}) \color{white}{+ \underbrace{a_m(u^{(i)}, \lambda) + b^{(i)}(\lambda)}_{=0 \vphantom{\forall u^{(i)} \in V}}}
										\]
									</div>
									<div class="fragment fade-in-then-out" data-fragment-index="2">
										\[
										\Sigma^{(i)} = c(u^{(i)}) + \underbrace{a_m(u^{(i)}, \lambda) + b^{(i)}(\lambda)}_{=0 \vphantom{\forall u^{(i)} \in V}}
									\]
									</div>
									<div class="fragment fade-in" data-fragment-index="3">
										\[
											\Sigma^{(i)} = \underbrace{c(u^{(i)}) + a_m(u^{(i)}, \lambda)}_{=0 \forall u^{(i)}} + b^{(i)}(\lambda)
										\]
									</div>
								</div>
							</li>
							<li class="fragment fade-in" data-fragment-index="4"> now we specify $\lambda \in V$ s.t.
								<div>
									\begin{align*}
										a_m(u, \lambda) + c(u) &= 0 \quad \forall u \in V \\
										\Sigma^{(i)} &= b^{(i)}(\lambda) \\
									\end{align*}
								</div>	
							</li>
							<li class="fragment fade-in" data-fragment-index="5">
								1st "application of an adjoint method"
								\begin{align*}
									a_m(u, \lambda) + c(u) &= 0 \quad \forall u \in V \\
									C = g_{\boldsymbol\Sigma} &= g_{\boldsymbol b(\lambda)} \\
									\nabla_p C &= \text{TODO!}
								\end{align*}
							</li>
						</ul>
					</div>
					</section>
					<section style="text-align: left;">
						<h3>(Simplified) abstract system</h3>
						We continue with
						<div> 
							\begin{align*}
								a_m(u, \lambda) + c(u) &= 0 \quad \forall u \in V \\
								C = g_{\boldsymbol\Sigma} &= g_{\boldsymbol b(\lambda)}
							\end{align*}
						</div>
						<ul style="width: 100%">
							<li class="fragment fade-in" data-fragment-index="1">
								derive sensitivity equations ($\dot{m}^{(n)} = \dot{\gamma}_p(e_n)$)
								<div class="r-stack">
									<span class="fragment fade-in-then-out" data-fragment-index="1">
										\begin{alignat*}{2}
											a_m(u, \dot{\lambda}^{(n)}) &+ \dot{a}_m(u, \lambda, \dot{m}^{(n)}) &&= 0 \quad \forall u \in V \\
											&\dot{C}^{(n)} = \dot{g}_{\boldsymbol \Sigma}(\boldsymbol b(\dot{\lambda}^{(n)}))
										\end{alignat*} 
									</span>
									<span class="fragment fade-in-then-out" data-fragment-index="2"> 
										\begin{alignat*}{2}
											a_m(u, \dot{\lambda}^{(n)}) &+ \beta^{(n)}(u) && = 0 \quad \forall u \in V \\
											&\dot{C}^{(n)} = \dot{g}_{\boldsymbol \Sigma}(\boldsymbol b(\dot{\lambda}^{(n)}))
										\end{alignat*}
									</span>
									<span class="fragment fade-in-then-out" data-fragment-index="3"> 
										\begin{alignat*}{2}
											a_m(u, \dot{\lambda}^{(n)}) &+ \beta^{(n)}(u) && = 0 \quad \forall u \in V \\
											&\dot{C}^{(n)} = \alpha(\dot{\lambda}^{(n)}) \hspace{19pt}
										\end{alignat*}
									</span>
									<span class="fragment fade-in-then-out" data-fragment-index="4"> 
										\begin{alignat*}{2}
											a_m(u, \dot{\lambda}^{(n)}) &+ \beta^{(n)}(u) && = 0 \quad \forall u \in V \\
											&\dot{C}^{(n)} = \alpha(\dot{\lambda}^{(n)}) \hspace{19pt}
										\end{alignat*} 
									</span>
									<span class="fragment fade-in" data-fragment-index="5">
										\begin{alignat*}{2}
											a_m(u, \dot{\lambda}^{(n)}) &+ \dot{a}_m(u, \lambda, \dot{m}^{(n)}) &&= 0 \quad \forall u \in V \\
											&\dot{C}^{(n)} = \dot{g}_{\boldsymbol \Sigma}(\boldsymbol b(\dot{\lambda}^{(n)}))
										\end{alignat*} 
									</span>
								</div> 
							</li>
							<li class=" fragment fade-in" data-fragment-index="4">
								second application of "an adjoint method" ($\bar{u} \in U$) <em>(continuous adjoint method)</em>
								<div class="r-stack">
									<span class="fragment fade-in-then-out" data-fragment-index="4">
										\begin{alignat*}{2}
											a_m(\bar{u}, \dot{\lambda}) &+ \alpha(\dot{\lambda}) && = 0 \quad \forall \dot{\lambda} \in V \\
											&\dot{C}^{(n)} = \beta^{(n)}(\bar{u}) \hspace{30pt}
										\end{alignat*}
									</span>
									<span class="fragment fade-in" data-fragment-index="5">
										\begin{alignat*}{2}
											a_m(\bar{u}, \dot{\lambda}) &+ \dot{g}_{\boldsymbol \Sigma}(\boldsymbol b(\dot{\lambda})) && = 0 \quad \forall \dot{\lambda} \in V \\
											&\dot{C}^{(n)} = \dot{a}_m(\bar{u}, \lambda, \dot{m}^{(n)})
										\end{alignat*}
									</span>
								</div>
							</li>
						</ul>
						<!-- if we mix in a little bit of notation from algorithmic differentiation
						\begin{align*}
							a_m(\bar{u}, \dot{\lambda}) + \bar{\boldsymbol \Sigma}^T \bar{\boldsymbol b}(\dot{\lambda}) = 0 \quad \forall \dot{\lambda} \in V\\
							\bar{m} = \bar{a}_m(\bar{u}, \lambda, \bar{C}) \\
							(\nabla_p C)_n = \bar{\gamma}_{p^{(n)}}(\bar{m}) 
						\end{align*} -->
						<!-- Together with the adjoint forward problem, we have:
						\begin{align*}
							a_m(u, \lambda) + c(u) &= 0 \quad \forall u \in V\\
							\Sigma^{(i)} &= b^{(i)}(\lambda)\\
							C &= g_{\boldsymbol \Sigma}\\
							\bar{\boldsymbol \Sigma} &= \bar{g}_{\boldsymbol{\Sigma}}(\bar{C})\\
							a_m(\bar{u}, \dot{\lambda}) + \bar{\boldsymbol \Sigma}^T \bar{\boldsymbol b}(\dot{\lambda}) &= 0 \quad \forall \dot{\lambda} \in V\\
							\bar{m} &= \bar{a}_m(\bar{u}, \lambda, \bar{C}) \\
							(\nabla_p C)_n &= \bar{\gamma}_{p^{(n)}}(\bar{m}) 
						\end{align*} -->
					</section>
					<section style="text-align: left;">
						<h3>Summary</h3>
						<div style="display:flex;">
							<div style="flex: 1;">
								<h4>naive implementation</h4>
								\begin{align*}
									a_m(u^{(i)}, v) + b^{(i)}(v) &= 0 \quad \forall v \in V \\
									\Sigma^{(i)} &= c(u^{(i)}) \\
									C &= g_{\boldsymbol \Sigma} \\
									a_m(\dot{u}^{(i, n)}, v) + \dot{a}_m(u^{(i)}, v, \dot{m}^{(n)}) &= 0 \quad \forall v \in V\\
									\dot{\Sigma}^{(i, n)} &= c(\dot{u}^{(i, n)}) \\
									(\nabla_p C)^{(n)} &= \dot{g}_{\boldsymbol \Sigma}(\dot{\boldsymbol \Sigma}^{(n)})
								\end{align*}
							</div>
							<div style="flex: 1;">
								<h4>adjoint$^2$ implementation</h4>
								\begin{align}
									a_m(u, \lambda) + c(u) &= 0 \quad \forall u \in V\\
									\boldsymbol \Sigma &= \boldsymbol b(\lambda) \\
									C &= g_{\boldsymbol \Sigma} \\
									a_m(\bar{u}, \dot{\lambda}) + \dot{g}_{\boldsymbol \Sigma}(\boldsymbol b(\dot{\lambda})) &= 0 \quad \forall \dot{\lambda} \in V \\
									(\nabla_p C)^{(n)} &= \dot{a}_m(\bar{u}, \lambda, \dot{m}^{(n)})\\
								\end{align}
							</div>
						</div>
						<h4>Generalizations:</h4>
						<ul>
							<li>$b^{(i)}(v) \rightsquigarrow b_m^{(i)}(v)$ (add to </li>
							<li>$c(u) \rightsquigarrow c_m^{(j)}(u)$</li>
							<li></li>
						</ul>
					</section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/

			Reveal.configure({pdfSeparateFragments: true});
			Reveal.initialize({
				hash: true,

				// The "normal" size of the presentation, aspect ratio will
				// be preserved when the presentation is scaled to fit different
				// resolutions. Can be specified using percentage units.
				width: 1920,
				height: 1440,

				// Factor of the display size that should remain empty around
				// the content
				margin: 0.1,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.01,
				maxScale: 2.0,
				center: false,

				transition: 'none',
				backgroundTransition: 'fade-in',

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath]
			});
		</script>
	</body>
</html>
